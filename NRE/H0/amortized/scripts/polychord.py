# %%
import h5py
import os
import time
import numpy as np
import matplotlib.pyplot as plt

from astropy.cosmology import FlatLambdaCDM
from astropy.constants import c
from astropy import units as u

c = c.to('Mpc/d')  # Speed of light

import pypolychord
from pypolychord.settings import PolyChordSettings
from pypolychord.priors import UniformPrior

import getdist.plots as plots

import torch
from networks import SetTransformer
from functions import r_estimator, normalization, gaussian_noise


# ----------------------------------- FUNCTIONS --------------------------------------

# NORM
def norm(x, y):
    return np.sqrt(x ** 2 + y ** 2)


# ROTATION MATRIX
def mtx_rot(phi):
    return np.array([[np.cos(phi), -np.sin(phi)],
                     [np.sin(phi), np.cos(phi)]])


def log_gaussian(x, mu, sigma):
    D = x.shape[0]
    log_gauss = -.5 * np.sum((x - mu) ** 2) / sigma ** 2 - D / 2 * np.log(2 * np.pi * sigma ** 2)
    return log_gauss


# CARTESIAN COORDINATES TO SPHERICAL
def cart2pol(x, y):
    return norm(x, y), np.arctan2(y, x)


# SPHERICAL COORDINATES TO CARTESIAN
def pol2cart(r, theta):
    return r * np.cos(theta), r * np.sin(theta)


def get_Fermat_potentials(x0_lens, y0_lens, ellip, phi, theta_E, gamma_ext, phi_ext, xim_fov, yim_fov, x0_AGN=0.,
                          y0_AGN=0.):
    f = ellip
    f_prime = np.sqrt(1 - f ** 2)

    # image coordinates in the lens coordinate system
    xim, yim = np.tensordot(mtx_rot(-phi), np.array([xim_fov - x0_lens, yim_fov - y0_lens]), axes=1)
    r_im, phi_im = cart2pol(yim, xim)
    # AGN coordinates in the lens coordinate system
    xsrc, ysrc = np.tensordot(mtx_rot(-phi), np.array([x0_AGN - x0_lens, y0_AGN - y0_lens]), axes=1)
    # Coordinate translation for the external shear
    xtrans, ytrans = np.tensordot(mtx_rot(-phi), np.array([x0_lens, y0_lens]), axes=1)

    # External shear in the lens coordinate system
    gamma1_fov, gamma2_fov = pol2cart(gamma_ext, phi_ext)
    gamma1, gamma2 = np.tensordot(mtx_rot(-2 * phi), np.array([gamma1_fov, gamma2_fov]), axes=1)

    # X deflection angle (eq. 27a Kormann et al. 1994)
    def alphax(varphi):
        return theta_E * np.sqrt(f) / f_prime * np.arcsin(f_prime * np.sin(varphi))

    # Y deflection angle (eq. 27a Kormann et al. 1994)
    def alphay(varphi):
        return theta_E * np.sqrt(f) / f_prime * np.arcsinh(f_prime / f * np.cos(varphi))

    # Lens potential deviation from a SIS (Meneghetti, 19_2018, psi_tilde)
    def psi_tilde(varphi):
        return np.sin(varphi) * alphax(varphi) + np.cos(varphi) * alphay(varphi)

    # Lens potential (eq. 26a Kormann et al. 1994)
    def lens_pot(varphi):
        return psi_tilde(varphi) * radial(varphi)

    # Shear potential (eq. 3.80 Meneghetti)
    def shear_pot(x, y):
        return gamma1 / 2 * (x ** 2 - y ** 2) + gamma2 * x * y

    # Radial componant (eq. 34 Kormann et al. 1994)
    def radial(varphi):
        usual_rad = ysrc * np.cos(varphi) + xsrc * np.sin(varphi) + psi_tilde(varphi)
        translation = gamma1 * (xtrans * np.sin(varphi) - ytrans * np.cos(varphi)) + gamma2 * (
                xtrans * np.cos(varphi) + ytrans * np.sin(varphi))
        shear_term = 1 + gamma1 * (np.cos(varphi) ** 2 - np.sin(varphi) ** 2) - 2 * gamma2 * np.cos(
            varphi) * np.sin(varphi)
        return (usual_rad + translation) / shear_term

    # Fermat potential
    geo_term = norm(xim - xsrc, yim - ysrc) ** 2 / 2
    lens_term = lens_pot(phi_im)
    shear_term = shear_pot(xim + xtrans, yim + ytrans)
    fermat_pot = geo_term - lens_term - shear_term

    fermat_pot = fermat_pot - np.min(fermat_pot)

    return fermat_pot


def get_time_delays(fermat, zd, Dd, Ds, Dds):
    """
    Function to integrate to estimate the posterior distribution
    Inputs
        fermat : (float) Potential value
        H0 : (float) H0 value
        zs : (float) Source's redshift
        zd : (float) Deflector's redshift
    Outputs
        time_delays : (float) Time delay generated by fermat
    """
    time_delays = (1 + zd) * Dd.value * Ds.value / Dds.value / c.value * fermat
    time_delays *= (2 * np.pi / 360 / 3600) ** 2  # Conversion to days

    return time_delays


def dumper(live, dead, logweights, logZ, logZerr):
    print("Last dead point:", dead[-1])


# ----------------------------------- GLOBAL VARIABLES --------------------------------------

path_out = "results/PolyChord/full_prior/"

# import keys
keys = h5py.File("data_plus/keys.hdf5", 'r')
test_keys = keys["test"][:]
keys.close()

# import data
dataset = h5py.File("data_plus/dataset.hdf5", 'r')
H0 = dataset["Hubble_cst"][test_keys]
lower_bound = np.floor(np.min(H0))
upper_bound = np.ceil(np.max(H0))

# remove out of bounds data
selected = np.array([20, 42, 33, 34, 43, 36, 13, 32, 10, 5])
idx_up = np.where(H0 > 75.)[0]
idx_down = np.where(H0 < 65.)[0]
idx_out = np.concatenate((idx_up, idx_down))
H0 = np.delete(H0, idx_out, axis=0)
H0 = H0[selected].flatten()
test_keys = np.delete(test_keys, idx_out, axis=0)
dt = dataset["time_delays"][test_keys][selected]
pot = dataset["Fermat_potential"][test_keys][selected]
z = dataset["redshifts"][test_keys][selected]
im_pos = dataset["positions"][test_keys][selected]
param = dataset["parameters"][test_keys][selected]
dataset.close()

sig_dt = .3
sig_pot = .003

nsamp = H0.shape[0]
npts = 1000
nDerived = 0
nDims = 8
settings = PolyChordSettings(nDims, nDerived)
settings.nlive = 500
settings.do_clustering = True
settings.read_resume = False

# ----------------------------------- NRE --------------------------------------

model = torch.load("results/SetTransformer/search2/1/models/trained_model.pt")

# reshape data
samples = np.concatenate((dt[:, :, None], pot[:, :, None]), axis=2)
samples = samples[samples != 0]
samples = samples.reshape(nsamp, 3, 2)

# observations
samples_repeated = torch.repeat_interleave(torch.from_numpy(samples), npts, dim=0)

# Global NRE posterior
support = np.linspace(lower_bound + 1, upper_bound - 1, npts).reshape(npts, 1)
support_tile = np.tile(support, (nsamp, 1))

dataset_test = torch.utils.data.TensorDataset(samples_repeated, torch.from_numpy(support_tile))
dataloader = torch.utils.data.DataLoader(dataset_test, batch_size=200)
ratios = []
for x1, x2 in dataloader:
    preds = r_estimator(model, x1, x2)
    ratios.extend(preds)

ratios = np.asarray(ratios).reshape(nsamp, npts)
support_tile = support_tile.reshape(nsamp, npts)
ratios = normalization(support_tile, ratios)

# ----------------------------------- Nested Sampling --------------------------------------

for i in range(nsamp):

    xim = im_pos[i, 0][im_pos[i, 0] != -1.]
    yim = im_pos[i, 1][im_pos[i, 1] != -1.]
    dt_obs = dt[i][dt[i] > 0]
    pot_obs = pot[i][pot[i] > 0]

    cosmo_model = FlatLambdaCDM(H0=H0[i], Om0=.3)
    Ds = cosmo_model.angular_diameter_distance(z[i, 1])
    Dd = cosmo_model.angular_diameter_distance(z[i, 0])
    Dds = cosmo_model.angular_diameter_distance_z1z2(z[i, 0], z[i, 1])

    settings.file_root = 'full_prior{}'.format(i)

    low = np.array([- .3, - .3, .30, - np.pi / 2, .5, 0., - np.pi / 2, H0[i] - 5.])
    high = np.array([.3, .3, .99, np.pi / 2, 2., 0.05, np.pi / 2, H0[i] + 5.])


    def prior(hypercube):
        """ Uniform prior from [-1,1]^D. """
        return low + hypercube * (high - low)


    def likelihood(theta):
        cosmo_model = FlatLambdaCDM(H0=theta[7], Om0=.3)
        Ds = cosmo_model.angular_diameter_distance(z[i, 1])
        Dd = cosmo_model.angular_diameter_distance(z[i, 0])
        Dds = cosmo_model.angular_diameter_distance_z1z2(z[i, 0], z[i, 1])

        pot = get_Fermat_potentials(theta[0], theta[1], theta[2], theta[3], theta[4],
                                    theta[5], theta[6], xim, yim)
        pot = pot[pot != 0].flatten()
        dt = get_time_delays(pot, z[i, 0], Dd, Ds, Dds)

        I = log_gaussian(dt_obs, dt, sig_dt) + log_gaussian(pot_obs, pot, sig_pot)

        return I, []


    lkh = likelihood(
        np.array([param[i, 0], param[i, 1], param[i, 2], param[i, 3], param[i, 4], param[i, 5], param[i, 6], H0[i]]))
    print(i, lkh)

    start = time.time()
    output = pypolychord.run_polychord(likelihood, nDims, nDerived, settings, prior, dumper)
    print(f'Integration completed {((time.time() - start) // 60):.0f}m {((time.time() - start) % 60):.0f}s')

    paramnames = [('xlens', r"x_{lens}"), ("ylens", r"y_{lens}"), ("f", r"f"), ("phi", r"\phi"),
                  ("theta_E", r"\theta_E"), ("gammaext", r"\gamma_{ext}"), ("phiext", r"\phi_{ext}"),
                  ("H0", r"H_{0}")]
    output.make_paramnames_files(paramnames)

    posterior = output.posterior
    g = plots.getSubplotPlotter()
    g.triangle_plot(posterior, filled=True,
                    markers={"xlens": param[i, 0], "ylens": param[i, 1], "f": param[i, 2], "phi": param[i, 3],
                             "theta_E": param[i, 4],
                             "gammaext": param[i, 5], "phiext": param[i, 6], "H0": H0[i]},
                    title_limit=1,
                    param_limits={"xlens": [low[0], high[0]], "ylens": [low[1], high[1]], "f": [low[2], high[2]],
                                  "phi": [low[3], high[3]], "theta_E": [low[4], high[4]], "gammaext": [low[5], high[5]],
                                  "phiext": [low[6], high[6]], "H0": [low[7], high[7]]})
    g.export(path_out + 'corner_plot{}.pdf'.format(i))

    # ----------------------------------- Figure --------------------------------------

    plt.style.use(['science', 'vibrant'])
    g = plots.get_subplot_plotter(width_inch=3, subplot_size_ratio=.776)
    g.settings.linewidth = 2
    g.plot_1d(posterior, 'H0', lims=[62, 78], normalized=True, colors=['C1'], ls=['--'])
    g.add_x_marker(H0[i], ls='dotted', lw=1.5)
    plt.plot(support.flatten(), ratios[i], '-', color='C4', zorder=0, linewidth=2)
    if i == 5:
        g.add_legend(['Nested' + '\n' + 'sampling', 'Truth', 'NRE'])
    if i in [0, 5]:
        plt.ylabel(r"$p(H_0 \mid \Delta t, \Delta \phi)$")
    else:
        plt.ylabel("")
    if i <= 4:
        plt.xlabel(r"H$_0$ (km Mpc$^{-1}$ s$^{-1}$)")
    else:
        plt.xlabel("")
    g.export(path_out + 'post{}.pdf'.format(i))