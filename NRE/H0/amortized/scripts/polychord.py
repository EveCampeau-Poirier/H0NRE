# %%
import h5py
import os
import numpy as np
import matplotlib.pyplot as plt

plt.style.use(['science', 'bright'])

from astropy.cosmology import FlatLambdaCDM
from astropy.constants import c
from astropy import units as u

c = c.to('Mpc/d')  # Speed of light

import pypolychord
from pypolychord.settings import PolyChordSettings
from pypolychord.priors import UniformPrior

import getdist.plots as plots

import torch
from networks import SetTransformer
from functions import r_estimator, normalization, gaussian_noise


# ----------------------------------- FUNCTIONS --------------------------------------

# NORM
def norm(x, y):
    return np.sqrt(x ** 2 + y ** 2)


# ROTATION MATRIX
def mtx_rot(phi):
    return np.array([[np.cos(phi), -np.sin(phi)],
                     [np.sin(phi), np.cos(phi)]])


def log_gaussian(x, mu, sigma):
    D = x.shape[0]
    log_gauss = -.5 * np.sum((x - mu) ** 2) / sigma ** 2 - D / 2 * np.log(2 * np.pi * sigma ** 2)
    return log_gauss


# CARTESIAN COORDINATES TO SPHERICAL
def cart2pol(x, y):
    return norm(x, y), np.arctan2(y, x)


# SPHERICAL COORDINATES TO CARTESIAN
def pol2cart(r, theta):
    return r * np.cos(theta), r * np.sin(theta)


def get_Fermat_potentials(x0_lens, y0_lens, ellip, phi, theta_E, gamma_ext, phi_ext, xim_fov, yim_fov, x0_AGN=0.,
                          y0_AGN=0.):
    f = ellip
    f_prime = np.sqrt(1 - f ** 2)

    # image coordinates in the lens coordinate system
    xim, yim = np.tensordot(mtx_rot(-phi), np.array([xim_fov - x0_lens, yim_fov - y0_lens]), axes=1)
    r_im, phi_im = cart2pol(yim, xim)
    # AGN coordinates in the lens coordinate system
    xsrc, ysrc = np.tensordot(mtx_rot(-phi), np.array([x0_AGN - x0_lens, y0_AGN - y0_lens]), axes=1)
    # Coordinate translation for the external shear
    xtrans, ytrans = np.tensordot(mtx_rot(-phi), np.array([x0_lens, y0_lens]), axes=1)

    # External shear in the lens coordinate system
    gamma1_fov, gamma2_fov = pol2cart(gamma_ext, phi_ext)
    gamma1, gamma2 = np.tensordot(mtx_rot(-2 * phi), np.array([gamma1_fov, gamma2_fov]), axes=1)

    # X deflection angle (eq. 27a Kormann et al. 1994)
    def alphax(varphi):
        return theta_E * np.sqrt(f) / f_prime * np.arcsin(f_prime * np.sin(varphi))

    # Y deflection angle (eq. 27a Kormann et al. 1994)
    def alphay(varphi):
        return theta_E * np.sqrt(f) / f_prime * np.arcsinh(f_prime / f * np.cos(varphi))

    # Lens potential deviation from a SIS (Meneghetti, 19_2018, psi_tilde)
    def psi_tilde(varphi):
        return np.sin(varphi) * alphax(varphi) + np.cos(varphi) * alphay(varphi)

    # Lens potential (eq. 26a Kormann et al. 1994)
    def lens_pot(varphi):
        return psi_tilde(varphi) * radial(varphi)

    # Shear potential (eq. 3.80 Meneghetti)
    def shear_pot(x, y):
        return gamma1 / 2 * (x ** 2 - y ** 2) + gamma2 * x * y

    # Radial componant (eq. 34 Kormann et al. 1994)
    def radial(varphi):
        usual_rad = ysrc * np.cos(varphi) + xsrc * np.sin(varphi) + psi_tilde(varphi)
        translation = gamma1 * (xtrans * np.sin(varphi) - ytrans * np.cos(varphi)) + gamma2 * (
                xtrans * np.cos(varphi) + ytrans * np.sin(varphi))
        shear_term = 1 + gamma1 * (np.cos(varphi) ** 2 - np.sin(varphi) ** 2) - 2 * gamma2 * np.cos(
            varphi) * np.sin(varphi)
        return (usual_rad + translation) / shear_term

    # Fermat potential
    geo_term = norm(xim - xsrc, yim - ysrc) ** 2 / 2
    lens_term = lens_pot(phi_im)
    shear_term = shear_pot(xim + xtrans, yim + ytrans)
    fermat_pot = geo_term - lens_term - shear_term

    fermat_pot = fermat_pot - np.min(fermat_pot)

    return fermat_pot


def get_time_delays(fermat, zd, Dd, Ds, Dds):
    """
    Function to integrate to estimate the posterior distribution
    Inputs
        fermat : (float) Potential value
        H0 : (float) H0 value
        zs : (float) Source's redshift
        zd : (float) Deflector's redshift
    Outputs
        time_delays : (float) Time delay generated by fermat
    """
    time_delays = (1 + zd) * Dd.value * Ds.value / Dds.value / c.value * fermat
    time_delays *= (2 * np.pi / 360 / 3600) ** 2  # Conversion to days

    return time_delays


def dumper(live, dead, logweights, logZ, logZerr):
    print("Last dead point:", dead[-1])


# ----------------------------------- GLOBAL VARIABLES --------------------------------------

path_out = "results/paper/SetTransformer/inference/"

selected = np.array([20, 42, 33, 34, 43, 36, 13, 32, 10, 5])
dataset = h5py.File("data_plus/dataset.hdf5", 'r')
keys = h5py.File("data_plus/keys.hdf5", 'r')
idx = keys["test"][:]
dt = dataset["time_delays"][idx][selected]
pot = dataset["Fermat_potential"][idx][selected]
im_pos = dataset["positions"][idx][selected]
z = dataset["redshifts"][idx][selected]
param = dataset["parameters"][idx][selected]
H0 = dataset["Hubble_cst"][idx][selected].flatten()
dataset.close()
keys.close()
sig_dt = .3
sig_pot = .003

nsamp = H0.shape[0]
npts = 1000
nDerived = 0
nDims = 8
settings = PolyChordSettings(nDims, nDerived)
settings.nlive = 500
settings.do_clustering = True
settings.read_resume = False

# ----------------------------------- NRE --------------------------------------

model = torch.load("results/SetTransformer/search2/1/models/trained_model.pt")

# reshape data
samples = np.concatenate((dt[:, :, None], pot[:, :, None]), axis=2)
samples = samples[samples != 0]
samples = samples.reshape(nsamp, 3, 2)

# observations
noisy_data = gaussian_noise(torch.from_numpy(samples))
noisy_data_repeated = torch.repeat_interleave(noisy_data, npts, dim=0)

# Global NRE posterior
support = np.linspace(60, 80, npts).reshape(npts, 1)
support_tile = np.tile(support, (nsamp, 1))

dataset_test = torch.utils.data.TensorDataset(noisy_data_repeated, torch.from_numpy(support_tile))
dataloader = torch.utils.data.DataLoader(dataset_test, batch_size=200)
ratios = []
for x1, x2 in dataloader:
    preds = r_estimator(model, x1, x2)
    ratios.extend(preds)

ratios = np.asarray(ratios).reshape(nsamp, npts)
support_tile = support_tile.reshape(nsamp, npts)
ratios = normalization(support_tile, ratios)

# ----------------------------------- Nested Sampling --------------------------------------

for i in range(nsamp):
    xim = im_pos[i, 0][im_pos[i, 0] != -1.]
    yim = im_pos[i, 1][im_pos[i, 1] != -1.]
    dt_obs = noisy_data[i, 0][noisy_data[i, 0] > 0].detach().cpu().numpy()
    pot_obs = noisy_data[i, 1][noisy_data[i, 1] > 0].detach().cpu().numpy()

    cosmo_model = FlatLambdaCDM(H0=H0[i], Om0=.3)
    Ds = cosmo_model.angular_diameter_distance(z[i, 1])
    Dd = cosmo_model.angular_diameter_distance(z[i, 0])
    Dds = cosmo_model.angular_diameter_distance_z1z2(z[i, 0], z[i, 1])
    vdisp = np.sqrt(param[i, 4] / 4 / np.pi / Dds.value * Ds.value / 180 / 3600 * np.pi) * c.value
    vdisp = (vdisp * u.Mpc / u.d).to('km/s').value

    settings.file_root = 'sample{}'.format(i)

    low = np.array([param[i, 0] - .1, param[i, 1] - .1, param[i, 2] - .1,
                    param[i, 3] - np.pi / 16, vdisp - 10., 0., param[i, 6] - np.pi / 16,
                    H0[i] - 5.])
    high = np.array([param[i, 0] + .1, param[i, 1] + .1, np.minimum(param[i, 2] + .1, .99),
                     param[i, 3] + np.pi / 16, vdisp + 10., .05, param[i, 6] + np.pi / 16,
                     H0[i] + 5.])


    def prior(hypercube):
        """ Uniform prior from [-1,1]^D. """
        return low + hypercube * (high - low)


    def likelihood(theta):
        cosmo_model = FlatLambdaCDM(H0=theta[7], Om0=.3)
        Ds = cosmo_model.angular_diameter_distance(z[i, 1])
        Dd = cosmo_model.angular_diameter_distance(z[i, 0])
        Dds = cosmo_model.angular_diameter_distance_z1z2(z[i, 0], z[i, 1])

        vdisp = (theta[4] * u.km / u.s).to('Mpc/d').value
        theta_E = 4 * np.pi * (vdisp / c.value) ** 2 * Dds.value / Ds.value * 180 * 3600 / np.pi

        pot = get_Fermat_potentials(theta[0], theta[1], theta[2], theta[3], theta_E,
                                    theta[5], theta[6], xim, yim)
        pot = pot[pot != 0].flatten()
        dt = get_time_delays(pot, z[0], Dd, Ds, Dds)

        I = log_gaussian(dt_obs, dt, sig_dt) + log_gaussian(pot_obs, pot, sig_pot)

        return I, []


    lkh = likelihood(
        np.array([param[i, 0], param[i, 1], param[i, 2], param[i, 3], vdisp, param[i, 5], param[i, 6], H0[i]]))
    print(i, lkh)

    output = pypolychord.run_polychord(likelihood, nDims, nDerived, settings, prior, dumper)

    paramnames = [('xlens', r"x_{lens}"), ("ylens", r"y_{lens}"), ("f", r"f"), ("phi", r"\phi"),
                  ("v", r"v"), ("gammaext", r"\gamma_{ext}"), ("phiext", r"\phi_{ext}"),
                  ("H0", r"H_{0}")]
    output.make_paramnames_files(paramnames)

    posterior = output.posterior
    g = plots.getSubplotPlotter()
    g.triangle_plot(posterior, filled=True,
                    markers={"xlens": param[i, 0], "ylens": param[i, 1], "f": param[i, 2], "phi": param[i, 3],
                             "v": vdisp,
                             "gammaext": param[i, 5], "phiext": param[i, 6], "H0": H0[i]},
                    title_limit=1)
    g.export(path_out + 'corner_plot{}.pdf'.format(i))

    # ----------------------------------- Figure --------------------------------------

    posterior = output.posterior
    g = plots.get_single_plotter(width_inch=4)
    g.plot_1d(posterior, 'H0', lims=[60, 80], normalized=True, colors=['C1'], ls=['-.'])
    g.add_x_marker(H0[i])
    plt.plot(support.flatten(), ratios[i], '-', color='C4', zorder=0)
    g.add_legend(['Nested sampling', 'Truth', 'NRE'])
    plt.ylabel(r"$p(H_0 \mid \Delta t, \Delta \phi)$")
    plt.xlabel(r"H$_0$ (km Mpc$^{-1}$ s$^{-1}$)")
    g.export(path_out + 'posterior{}.pdf'.format(i))